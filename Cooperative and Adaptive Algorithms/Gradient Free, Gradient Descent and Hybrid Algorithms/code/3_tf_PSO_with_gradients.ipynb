{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. tf-PSO-with-gradients.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QltQJcQxvcV",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-M2v3IPxtk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "from functools import reduce\n",
        "import operator\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import random\n",
        "import layers\n",
        "import math\n",
        "import argparse\n",
        "import parseutils as pu\n",
        "import utils\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from layers import maxclip, fc\n",
        "# from utils import msgtime, str_memusage, print_prog_bar, fcn_stats\n",
        "import csv\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6Z8D4USxxrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up random seeds\n",
        "seed = 1234\n",
        "np.random.seed(seed)\n",
        "tf.set_random_seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yvipj8Tx1fF",
        "colab_type": "text"
      },
      "source": [
        "##  Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-XE7BAwx0Gt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv('Iris_Dataset.csv')\n",
        "dataset = pd.get_dummies(dataset, columns=['Species']) # One Hot Encoding\n",
        "values = list(dataset.columns.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYfw50erx8HF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = dataset[values[-3:]]\n",
        "y = np.array(y, dtype='float32')\n",
        "X = dataset[values[1:-3]]\n",
        "X = np.array(X, dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqXlb9WtyGLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shuffle Data\n",
        "indices = np.random.choice(len(X), len(X), replace=False)\n",
        "X_values = X[indices]\n",
        "y_values = y[indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXwP6ZCTyIr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a Train and a Test Dataset\n",
        "test_size = 50\n",
        "X_test = X_values[-test_size:]\n",
        "X_train = X_values[:-test_size]\n",
        "y_test = y_values[-test_size:]\n",
        "y_train = y_values[:-test_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dUpriYyUHfi",
        "colab_type": "text"
      },
      "source": [
        "## Set up models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT_cxJF-Kij5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_config = dict(\n",
        "    N_IN = 4,                            # Number of Feature Inputs\n",
        "    N_BATCHSIZE = 32,                    # Batch size\n",
        "    N_PARTICLES = 32,                    # Number of Particles\n",
        "    G_BEST_FACTOR = 0.8,                 # Global Best for PSO\n",
        "    L_BEST_FACTOR = 0.7,                 # Local Best for PSO\n",
        "    P_BEST_FACTOR = 0.6,                 # Personal Best for PSO\n",
        "    VELOCITY_DECAY = 1,                  # Decay in velocity after each position update\n",
        "    MAX_VEL = 0.005,                     # Maximum velocity for a particle if restricted\n",
        "    MAX_VEL_DECAY = 1,                   # Multiplier for Max Velocity with each update\n",
        "    N_ITERATIONS = int(1e2),             # Number of iterations\n",
        "    HIDDEN_LAYERS = [3, 2],              # Hidden layer dim\n",
        "    LEARNING_RATE = 0.1,                  # Learning Rate\n",
        "\n",
        "    # Other Params for image similarity\n",
        "    c1=tf.constant(2.05,dtype=None,shape=None,name='c1'),\n",
        "    c2=tf.constant(2.05,dtype=None,shape=None,name='c2'),\n",
        "    chi = abs(2.0 / (2.0 - 4.1 - math.sqrt(4.1 * 4.1 - 4.0 * 4.1)))\n",
        "    )\n",
        "\n",
        "LAYERS = [base_config[\"N_IN\"]] + base_config[\"HIDDEN_LAYERS\"] + [3]\n",
        "t_VELOCITY_DECAY = tf.constant(value=base_config[\"VELOCITY_DECAY\"],\n",
        "                               dtype=tf.float32,\n",
        "                               name='vel_decay')\n",
        "t_MVEL = tf.Variable(base_config[\"MAX_VEL\"],\n",
        "                     dtype=tf.float32,\n",
        "                     name='vel_restrict')\n",
        "net_in = tf.placeholder(dtype=tf.float32,\n",
        "                        shape=[None, 4],\n",
        "                        name='net_in')\n",
        "label = tf.placeholder(dtype=tf.float32,\n",
        "                           shape=[None, 3],\n",
        "                           name='net_label')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T8uVIbvYfuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MULTI-PARTICLE NEURAL NETS\n",
        "losses = []\n",
        "nets = []\n",
        "pweights = []\n",
        "pbiases = []\n",
        "vweights = []\n",
        "vbiases = []\n",
        "pfitlist = []\n",
        "pweightslist=[]\n",
        "vweightslist=[]\n",
        "pbiaseslist=[]\n",
        "vbiaseslist=[]\n",
        "weightslist=[]\n",
        "biaseslist=[]\n",
        "netlist=[]\n",
        "len_weights=tf.placeholder(dtype=tf.int32,shape=[])\n",
        "random_values = []\n",
        "accuracy_updates=[]\n",
        "\n",
        "# Positional Updates\n",
        "bias_updates = []\n",
        "weight_updates = []\n",
        "\n",
        "# Velocity Updates\n",
        "vweight_updates = []\n",
        "vbias_updates = []\n",
        "\n",
        "# Fitness Updates\n",
        "fit_updates = []\n",
        "\n",
        "# Control Updates - Controling PSO inside tf.Graph\n",
        "control_updates = []\n",
        "\n",
        "# Hybrid Updates - Using of PSO + Traditional Approaches\n",
        "hybrid_updates = []\n",
        "\n",
        "# Global Best\n",
        "gweights = []\n",
        "gbiases = []\n",
        "gfit = tf.Variable(math.inf, name='gbestfit')\n",
        "\n",
        "# Local Best\n",
        "lweights= []\n",
        "lbiases =[]\n",
        "lfitlist=[]\n",
        "lweightslist=[]\n",
        "lbiaseslist=[]\n",
        "lbestindex = tf.Variable(math.inf, name='lbestindex')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyV3-WCfYbw9",
        "colab_type": "code",
        "outputId": "8da12b44-c220-470a-dda9-59ade1b0bd88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "for pno in range(base_config[\"N_PARTICLES\"]):\n",
        "    weights = []\n",
        "    biases = []\n",
        "    pweights = []\n",
        "    pbiases = []\n",
        "    pbestrand = tf.Variable(tf.random_uniform(\n",
        "        shape=[], maxval=base_config[\"P_BEST_FACTOR\"]),\n",
        "        name='pno' + str(pno + 1) + 'pbestrand')\n",
        "    gbestrand = tf.Variable(tf.random_uniform(\n",
        "    shape=[], maxval=base_config[\"G_BEST_FACTOR\"]),\n",
        "    name='pno' + str(pno + 1) + 'gbestrand')\n",
        "\n",
        "    # Append the random values so that the initializer can be called again\n",
        "    random_values.append(pbestrand)\n",
        "    random_values.append(gbestrand)\n",
        "    pfit = tf.Variable(math.inf, name='pno' + str(pno + 1) + 'fit')\n",
        "    net = net_in\n",
        "    # Define the parameters\n",
        "\n",
        "    for idx, num_neuron in enumerate(LAYERS[1:]):\n",
        "        layer_scope = 'pno' + str(pno + 1) + 'fc' + str(idx + 1)\n",
        "        net, pso_tupple = fc(input_tensor=net,\n",
        "                             n_output_units=num_neuron,\n",
        "                             activation_fn='sigmoid',\n",
        "                             scope=layer_scope,\n",
        "                             uniform=True)\n",
        "        w, b, pw, pb, vw, vb = pso_tupple\n",
        "        vweights.append(vw)\n",
        "        vbiases.append(vb)\n",
        "        vweightslist.append(pw)\n",
        "        vbiaseslist.append(pb)\n",
        "        weights.append(w)\n",
        "        weightslist.append(w)\n",
        "        biaseslist.append(b)\n",
        "        biases.append(b)\n",
        "        pweights.append(pw)\n",
        "        pbiases.append(pb)\n",
        "        pweightslist.append(pw)\n",
        "        pbiaseslist.append(pb)\n",
        "        netlist.append(net)\n",
        "        lw = tf.Variable(tf.random_uniform(\n",
        "                shape=[LAYERS[idx],LAYERS[idx+1]],\n",
        "                dtype=tf.float32),\n",
        "                name='lw')\n",
        "        lb = tf.Variable(tf.random_uniform(\n",
        "                shape=[LAYERS[idx+1]],\n",
        "                dtype=tf.float32),\n",
        "                name='lb')\n",
        "        lweightslist.append(lw)\n",
        "        lbiaseslist.append(lb)\n",
        "\n",
        "        nextvw = tf.multiply(vw, t_VELOCITY_DECAY)\n",
        "        nextvb = tf.multiply(vb, t_VELOCITY_DECAY)\n",
        "\n",
        "        # Differences between Particle Best & Current\n",
        "        pdiffw = tf.multiply(tf.subtract(pw, w), pbestrand)\n",
        "        pdiffb = tf.multiply(tf.subtract(pb, b), pbestrand)\n",
        "        # Define & Reuse the GBest\n",
        "        gw = None\n",
        "        gb = None\n",
        "        with tf.variable_scope(\"gbest\", reuse=tf.AUTO_REUSE):\n",
        "            gw = tf.get_variable(name='fc' + str(idx + 1) + 'w',\n",
        "                             shape=[LAYERS[idx], LAYERS[idx + 1]],\n",
        "                             initializer=tf.zeros_initializer)\n",
        "\n",
        "            gb = tf.get_variable(name='fc' + str(idx + 1) + 'b',\n",
        "                             shape=[LAYERS[idx + 1]],\n",
        "                             initializer=tf.zeros_initializer)\n",
        "\n",
        "        # If first Particle add to Global Else it is already present\n",
        "\n",
        "        if pno == 0:\n",
        "            gweights.append(gw)\n",
        "            gbiases.append(gb)\n",
        "\n",
        "        # Differences between Global Best & Current\n",
        "        gdiffw = tf.multiply(tf.subtract(gw, w), gbestrand)\n",
        "        gdiffb = tf.multiply(tf.subtract(gb, b), gbestrand)\n",
        "        vweight_update = None\n",
        "        vweight_update = tf.assign(vw,\n",
        "                                 tf.add_n([nextvw, pdiffw, gdiffw]),\n",
        "                                 validate_shape=True)\n",
        "       \n",
        "\n",
        "        vweight_updates.append(vweight_update)\n",
        "        vbias_update = None\n",
        "        vbias_update = tf.assign(vb,\n",
        "                                 tf.add_n([nextvb, pdiffb, gdiffb]),\n",
        "                                 validate_shape=True)\n",
        "        vbias_updates.append(vbias_update)\n",
        "        weight_update = tf.assign(w, w + vw, validate_shape=True)\n",
        "        weight_updates.append(weight_update)\n",
        "        bias_update = tf.assign(b, b + vb, validate_shape=True)\n",
        "        bias_updates.append(bias_update)\n",
        "\n",
        "\n",
        "    loss = tf.reduce_mean(-tf.reduce_sum(label* tf.log(net), axis=0))\n",
        "    correct_prediction = tf.equal(tf.argmax(net, 1), tf.argmax(label, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    accuracy_updates.append(accuracy)\n",
        "    particlebest = tf.cond(loss < pfit, lambda: loss, lambda: pfit)\n",
        "    fit_update = tf.assign(pfit, particlebest, validate_shape=True)\n",
        "    fit_updates.append(fit_update)\n",
        "    globalbest = tf.cond(loss < gfit, lambda: loss, lambda: gfit)\n",
        "    fit_update = tf.assign(gfit, globalbest, validate_shape=True)\n",
        "    fit_updates.append(fit_update)\n",
        "    pfitlist.append(pfit)\n",
        "    control_update = tf.assign(t_MVEL, tf.multiply(t_MVEL,base_config[\"MAX_VEL_DECAY\"]),validate_shape=True)\n",
        "    control_updates.append(control_update)\n",
        "\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=base_config[\"LEARNING_RATE\"])\n",
        "    hybrid_update = optimizer.minimize(loss)\n",
        "    hybrid_updates.append(hybrid_update)\n",
        "    assert len(weights) == len(biases)\n",
        "    assert len(gweights) == len(gbiases)\n",
        "    assert len(pweights) == len(pbiases)\n",
        "    assert len(gweights) == len(weights)\n",
        "    assert len(pweights) == len(weights)\n",
        "\n",
        "    for i in range(len(weights)):\n",
        "        # Particle Best\n",
        "        pweight = tf.cond(loss < pfit, lambda: weights[i], lambda: pweights[i])\n",
        "        fit_update = tf.assign(pweightslist[pno*len(weights)+i], pweight, validate_shape=True)\n",
        "        fit_update = tf.assign(pweights[i], pweight, validate_shape=True)\n",
        "        fit_updates.append(fit_update)\n",
        "        pbias = tf.cond(loss < pfit, lambda: biases[i], lambda: pbiases[i])\n",
        "        fit_update = tf.assign(pbiaseslist[pno*len(weights)+i], pbias, validate_shape=True)\n",
        "        fit_update = tf.assign(pbiases[i], pbias, validate_shape=True)\n",
        "        fit_updates.append(fit_update)\n",
        "\n",
        "        # Global Best\n",
        "        gweight = tf.cond(loss < gfit, lambda: weights[i], lambda: gweights[i])\n",
        "        netlist[0]=net\n",
        "        fit_update = tf.assign(gweights[i], gweight, validate_shape=True)\n",
        "\n",
        "        fit_updates.append(fit_update)\n",
        "        gbias = tf.cond(loss < gfit, lambda: biases[i], lambda: gbiases[i])\n",
        "        fit_update = tf.assign(gbiases[i], gbias, validate_shape=True)\n",
        "        fit_updates.append(fit_update)\n",
        "    nets.append(net)\n",
        "    losses.append(loss)\n",
        "    len_weights=len(weights)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0806 04:32:24.034538 140479858325376 deprecation_wrapper.py:119] From /content/layers.py:30: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0806 04:32:24.036924 140479858325376 deprecation_wrapper.py:119] From /content/layers.py:33: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0806 04:32:24.052582 140479858325376 deprecation.py:323] From /content/layers.py:50: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB-ERZxCUvcw",
        "colab_type": "code",
        "outputId": "25b08f00-c383-426b-c124-3e7c9086d125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "source": [
        "vweights=[]\n",
        "vbiases=[]\n",
        "\n",
        "# Initialize the entire graph\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Define the updates which are to be done before each iterations\n",
        "random_updates = [r.initializer for r in random_values]\n",
        "updates = weightslist + biaseslist + \\\n",
        "    random_updates + vbiaseslist + vweightslist + \\\n",
        "    fit_updates + control_updates + hybrid_updates + pweightslist + pbiaseslist\n",
        "req_list = losses, updates, gfit, gbiases, vweights, vbiases, gweights,accuracy_updates,nets\n",
        "original_nets=nets\n",
        "iter_list = []\n",
        "acc_list = []\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    max_accuracy=0\n",
        "    for i in range(base_config[\"N_ITERATIONS\"]):\n",
        "        # Reinitialize the Random Values at each iteration\n",
        "        sess.run(hybrid_update,feed_dict={net_in: X_train, label: y_train})\n",
        "\n",
        "        _tuple = sess.run(req_list, feed_dict={\n",
        "            net_in: X_train, label: y_train})\n",
        "        _losses = None\n",
        "        _losses, _, gfit, gbiases, vweights, vbiases, gweights, accuracy_updates, nets = _tuple\n",
        "\n",
        "        if (i + 1) % 1 == 0:\n",
        "            iter_list.append(i+1)\n",
        "            if max(accuracy_updates)>max_accuracy:\n",
        "                max_accuracy=max(accuracy_updates)\n",
        "            acc_list.append(max_accuracy)\n",
        "        if (i + 1) % 50 == 0:\n",
        "          print('Iteration:', i+1,  '\\n', 'Losses:', _losses,)\n",
        "          print('accuracy', max_accuracy)\n",
        "\n",
        "    best_particle,_ = min(enumerate(_losses), key=operator.itemgetter(1))\n",
        "    \n",
        "    # Close the writer\n",
        "    plt.plot(iter_list, acc_list)\n",
        "    plt.xlabel(\"iterations\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.show()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 50 \n",
            " Losses: [36.588604, 78.78354, 16.639221, 36.92377, 50.68547, 36.620285, 36.90539, 37.00072, 36.769096, 52.612488, 36.59885, 18.213428, 36.62853, 70.88398, 34.920208, 29.270243, 52.065723, 29.270773, 20.67732, 36.618633, 36.58134, 24.203867, 25.216177, 24.268969, 36.57679, 36.744274, 36.616764, 37.732784, 36.576687, 36.914433, 41.817806, 36.580444]\n",
            "accuracy 0.76\n",
            "Iteration: 100 \n",
            " Losses: [36.576874, 36.845123, 15.533658, 36.756092, 36.9913, 36.620296, 36.57796, 36.826458, 36.57757, 36.664276, 36.576954, 15.242507, 36.591824, 18.072151, 19.169968, 20.139517, 36.588814, 19.166136, 15.488833, 36.59936, 36.576683, 24.18041, 23.909662, 24.1913, 36.576656, 36.5777, 36.615868, 36.594376, 36.576664, 36.577, 36.623646, 36.57666]\n",
            "accuracy 0.76\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76UQXLN-xUXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}